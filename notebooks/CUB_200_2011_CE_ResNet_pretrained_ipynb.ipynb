{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCJXrk_vwwlV"
      },
      "source": [
        "# ResNet with CrossEntropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import datetime\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "import torch.backends.cudnn as cudnn\n",
        "from functools import wraps\n",
        "from dataclasses import dataclass\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zxiOEZfNRJa",
        "outputId": "dec61660-983f-4b0f-a212-79aecc629931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Aug 21 02:29:58 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   51C    P8             12W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRXy8AX1Ih_5"
      },
      "source": [
        "## Dataset Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "smVYU_J2JL4O"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = \"/content/cub-200-2011/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_sAoDdBdXWq",
        "outputId": "3056c3c5-1b90-4151-951e-f977c15d161d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-08-21 02:30:12--  https://s3.amazonaws.com/fast-ai-imageclas/CUB_200_2011.tgz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.46.86, 16.15.219.121, 52.217.75.62, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.46.86|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1150585339 (1.1G) [application/x-tar]\n",
            "Saving to: ‘CUB_200_2011.tgz’\n",
            "\n",
            "CUB_200_2011.tgz    100%[===================>]   1.07G  17.2MB/s    in 67s     \n",
            "\n",
            "2025-08-21 02:31:20 (16.5 MB/s) - ‘CUB_200_2011.tgz’ saved [1150585339/1150585339]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3.amazonaws.com/fast-ai-imageclas/CUB_200_2011.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c--1_eCry-AF"
      },
      "outputs": [],
      "source": [
        "!tar -xf /content/CUB_200_2011.tgz -C /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMoC1eGOAmvP"
      },
      "source": [
        "## Difine seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CvG9FPwS4McW"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=200):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # optional\n",
        "    # for numpy.random\n",
        "    np.random.seed(seed)\n",
        "    # for built-in random\n",
        "    random.seed(seed)\n",
        "    # for hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHVON8rSNbFR"
      },
      "source": [
        "## Define ResNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5Fkl640Ps2u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class Feature(nn.Module):\n",
        "    def __init__(self, model='resnet18'):\n",
        "        nn.Module.__init__(self)\n",
        "        self.model = model\n",
        "\n",
        "        self.base = models.__dict__[model](weights='IMAGENET1K_V1')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base.conv1(x)\n",
        "        x = self.base.bn1(x)\n",
        "        x = self.base.relu(x)\n",
        "        x = self.base.maxpool(x)\n",
        "\n",
        "        x = self.base.layer1(x)\n",
        "        x = self.base.layer2(x)\n",
        "        x = self.base.layer3(x)\n",
        "        x = self.base.layer4(x)\n",
        "\n",
        "        x = self.base.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "def resnet18_pretrain(**kwargs):\n",
        "    return Feature('resnet18')\n",
        "\n",
        "def resnet34_pretrain(**kwargs):\n",
        "    return Feature('resnet34')\n",
        "\n",
        "def resnet50_pretrain(**kwargs):\n",
        "    return Feature('resnet50')\n",
        "\n",
        "model_dict = {\n",
        "    'resnet18_pretrain': [resnet18_pretrain, 512],\n",
        "    'resnet34_pretrain': [resnet34_pretrain, 512],\n",
        "    'resnet50_pretrain': [resnet50_pretrain, 2048],\n",
        "}\n",
        "\n",
        "\n",
        "class SupCEResNet(nn.Module):\n",
        "    \"\"\"encoder + classifier\"\"\"\n",
        "    def __init__(self, name='resnet50', num_classes=10):\n",
        "        super(SupCEResNet, self).__init__()\n",
        "        model_fun, dim_in = model_dict[name]\n",
        "        self.encoder = model_fun()\n",
        "        self.fc = nn.Linear(dim_in, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(self.encoder(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAd9WdXUSIAi"
      },
      "source": [
        "## Define Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afhHQQDvQ6tI"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Option():\n",
        "    dataset: str = 'cub-200-2011'\n",
        "    model: str = 'resnet18_pretrain'\n",
        "    batch_size: int = 128\n",
        "    num_workers: int = 2\n",
        "    epochs: int = 300\n",
        "    learning_rate: float = 0.2\n",
        "    lr_decay_epochs: str = '200,240,270'\n",
        "    lr_decay_rate: float = 0.1\n",
        "    weight_decay: float = 1e-4\n",
        "    momentum: float = 0.9\n",
        "    cosine: bool = True\n",
        "    warm: bool = True\n",
        "    temp: float = 0.1\n",
        "    trial: int = 5\n",
        "    seed: int = 44\n",
        "    n_cls: int = 200\n",
        "\n",
        "opt = Option()\n",
        "\n",
        "set_seed(opt.seed)\n",
        "opt.model_path = f'seed{opt.seed}_{opt.model}_CrossEntropy_epoch_{opt.epochs}_batch_size_{opt.batch_size}_trial_{opt.trial}'\n",
        "opt.tb_dir = f'{BASE_PATH}/tensorboards/{opt.dataset}'\n",
        "if not os.path.isdir(opt.tb_dir):\n",
        "    os.makedirs(opt.tb_dir)\n",
        "\n",
        "opt.checkpoint_dir = f'{BASE_PATH}/checkpoints/{opt.dataset}'\n",
        "if not os.path.isdir(opt.checkpoint_dir):\n",
        "    os.makedirs(opt.checkpoint_dir)\n",
        "\n",
        "iterations = opt.lr_decay_epochs.split(',')\n",
        "opt.lr_decay_epochs = list([])\n",
        "for it in iterations:\n",
        "    opt.lr_decay_epochs.append(int(it))\n",
        "\n",
        "if opt.cosine:\n",
        "    opt.model_path = '{}_cosine'.format(opt.model_path)\n",
        "# warm-up for large-batch training,\n",
        "if opt.batch_size > 256:\n",
        "    opt.warm = True\n",
        "if opt.warm:\n",
        "    opt.model_path = '{}_warm'.format(opt.model_path)\n",
        "    opt.warmup_from = 0.01\n",
        "    opt.warm_epochs = 10\n",
        "    if opt.cosine:\n",
        "        eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
        "        opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
        "                1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
        "    else:\n",
        "        opt.warmup_to = opt.learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PduKISi2lr6r"
      },
      "outputs": [],
      "source": [
        "def adjust_learning_rate(args, optimizer, epoch):\n",
        "    lr = args.learning_rate\n",
        "    if args.cosine:\n",
        "        eta_min = lr * (args.lr_decay_rate ** 3)\n",
        "        lr = eta_min + (lr - eta_min) * (\n",
        "                1 + math.cos(math.pi * epoch / args.epochs)) / 2\n",
        "    else:\n",
        "        steps = np.sum(epoch > np.asarray(args.lr_decay_epochs))\n",
        "        if steps > 0:\n",
        "            lr = lr * (args.lr_decay_rate ** steps)\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def warmup_learning_rate(args, epoch, batch_id, total_batches, optimizer):\n",
        "    if args.warm and epoch <= args.warm_epochs:\n",
        "        p = (batch_id + (epoch - 1) * total_batches) / \\\n",
        "            (args.warm_epochs * total_batches)\n",
        "        lr = args.warmup_from + p * (args.warmup_to - args.warmup_from)\n",
        "\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BapIeXUsSIAk"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JdRDNq2sMN93"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIpMsoAIIssi"
      },
      "source": [
        "## DataLoader Define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nO1r9YbgXkvI"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class CUBDataset(Dataset):\n",
        "    def __init__(self, root, split=\"train\", transform=None, use_bbox=True):\n",
        "        self.root      = Path(root)\n",
        "        self.transform = transform\n",
        "        self.split     = split\n",
        "        self.use_bbox  = use_bbox\n",
        "\n",
        "        # --- ① ファイルをパース ------------------------------------------------\n",
        "        self.img_paths = {}   # id -> relative path\n",
        "        self.labels    = {}   # id -> 0-based label\n",
        "        self.is_train  = {}   # id -> bool\n",
        "\n",
        "        with open(self.root / \"images.txt\") as f:\n",
        "            for line in f:\n",
        "                img_id, rel = line.strip().split()\n",
        "                self.img_paths[int(img_id)] = rel\n",
        "\n",
        "        with open(self.root / \"image_class_labels.txt\") as f:\n",
        "            for line in f:\n",
        "                img_id, lbl = line.strip().split()\n",
        "                self.labels[int(img_id)] = int(lbl) - 1  # 0-start\n",
        "\n",
        "        with open(self.root / \"train_test_split.txt\") as f:\n",
        "            for line in f:\n",
        "                img_id, flag = line.strip().split()\n",
        "                self.is_train[int(img_id)] = (flag == \"1\")\n",
        "\n",
        "        # --- ② バウンディングボックス ------------------------------------------\n",
        "        # bounding_boxes.txt: <id> <x> <y> <w> <h>\n",
        "        self.bboxes = {}\n",
        "        if self.use_bbox:\n",
        "            with open(self.root / \"bounding_boxes.txt\") as f:\n",
        "                for line in f:\n",
        "                    img_id, x, y, w, h = map(float, line.strip().split())\n",
        "                    self.bboxes[int(img_id)] = (x, y, x + w, y + h)\n",
        "\n",
        "        # --- ③ split でフィルタ -------------------------------------------------\n",
        "        self.ids = [\n",
        "            i for i in self.img_paths\n",
        "            if (self.is_train[i] if split == \"train\" else not self.is_train[i])\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id   = self.ids[idx]\n",
        "        img_path = self.root / \"images\" / self.img_paths[img_id]\n",
        "        label    = self.labels[img_id]\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # --- ④ BBox で Crop -----------------------------------------------------\n",
        "        if self.use_bbox:\n",
        "            x1, y1, x2, y2 = self.bboxes[img_id]\n",
        "            img = img.crop((x1, y1, x2, y2))\n",
        "\n",
        "        # --- ⑤ transform 適用 ----------------------------------------------------\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8nTfwmmtQA-T"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((600, 600), Image.BILINEAR),\n",
        "    transforms.RandomCrop((448, 448)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((600, 600), Image.BILINEAR),\n",
        "    transforms.CenterCrop((448, 448)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_ds = CUBDataset(\"/content/CUB_200_2011\", split=\"train\", transform=transform_train, use_bbox=False)\n",
        "test_ds  = CUBDataset(\"/content/CUB_200_2011\", split=\"test\" , transform=transform, use_bbox=False)\n",
        "\n",
        "train_loader = DataLoader(train_ds,\n",
        "                          batch_size=opt.batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=opt.num_workers)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=1\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dfSy5kIUH03k"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tb_log_dir = f'{opt.tb_dir}/{opt.model_path}/{current_time}'\n",
        "\n",
        "writer = SummaryWriter(log_dir=tb_log_dir, flush_secs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVTbB3LqHlAw"
      },
      "source": [
        "# training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d_AM7UZKVsN",
        "outputId": "1890e266-5675-41a9-dc5e-5dfbc352281d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 229MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SupCEResNet(\n",
              "  (encoder): Feature(\n",
              "    (base): ResNet(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "      (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=512, out_features=200, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SupCEResNet(name=opt.model, num_classes=opt.n_cls)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZX-QJW1vNM-0"
      },
      "outputs": [],
      "source": [
        "def train(model, trainloader, optimizer, criterion, opt, epoch, writer):\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    for idx, (images, labels) in enumerate(trainloader):\n",
        "      #\n",
        "      if torch.cuda.is_available():\n",
        "          images = images.cuda(non_blocking=True)\n",
        "          labels = labels.cuda(non_blocking=True)\n",
        "\n",
        "      bsz = labels.shape[0]\n",
        "      warmup_learning_rate(opt, epoch, idx, len(trainloader), optimizer)\n",
        "      output = model(images)\n",
        "      loss = criterion(output, labels)\n",
        "\n",
        "      # SGD\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # measure accuracy and record loss\n",
        "      acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
        "      losses.update(loss.item(), bsz)\n",
        "      top1.update(acc1[0], bsz)\n",
        "      top5.update(acc5[0], bsz)\n",
        "\n",
        "    writer.add_scalar('train/loss', losses.avg, epoch)\n",
        "    writer.add_scalar('train/accuracy_top1', top1.avg, epoch)\n",
        "    writer.add_scalar('train/accuracy_top5', top5.avg, epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "29w-CJ8fNkeH"
      },
      "outputs": [],
      "source": [
        "def validation(model, valloader, criterion, writer, epoch):\n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valloader:\n",
        "            if torch.cuda.is_available():\n",
        "              images = images.cuda(non_blocking=True)\n",
        "              labels = labels.cuda(non_blocking=True)\n",
        "            bsz = labels.shape[0]\n",
        "\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "            # measure accuracy and record loss\n",
        "            acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
        "            losses.update(loss.item(), bsz)\n",
        "            top1.update(acc1[0], bsz)\n",
        "            top5.update(acc5[0], bsz)\n",
        "\n",
        "    writer.add_scalar('test/loss', losses.avg, epoch)\n",
        "    writer.add_scalar('test/accuracy_top1', top1.avg, epoch)\n",
        "    writer.add_scalar('test/accuracy_top5', top5.avg, epoch)\n",
        "    return top1.avg, top5.avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJb1BiBoQOyJ",
        "outputId": "438c8a83-38cc-410d-9b27-5c48aa218fb4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "train_loss_results = []\n",
        "train_contrastive_loss_results = []\n",
        "best_loss = 80\n",
        "best_accuracy = 0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(),\n",
        "                            lr=opt.learning_rate,\n",
        "                            momentum=opt.momentum,\n",
        "                            weight_decay=opt.weight_decay)\n",
        "\n",
        "for epoch in tqdm(range(1, opt.epochs + 1)):\n",
        "\n",
        "  adjust_learning_rate(opt, optimizer, epoch)\n",
        "\n",
        "  train(model, train_loader, optimizer, criterion, opt, epoch, writer)\n",
        "\n",
        "  top1, top5 = validation(model, test_loader, criterion, writer, epoch)\n",
        "  state = {'epoch': epoch,\n",
        "           'model': opt.model,\n",
        "           'state_dict': model.state_dict(),\n",
        "           'best_acc1': best_accuracy,\n",
        "           'optimizer' : optimizer.state_dict(),}\n",
        "\n",
        "  torch.save(state, f\"{opt.checkpoint_dir}/{opt.model_path}_last.pth.tar\")\n",
        "  if best_accuracy < top1:\n",
        "    best_accuracy = top1\n",
        "    print(best_accuracy)\n",
        "    shutil.copyfile(f\"{opt.checkpoint_dir}/{opt.model_path}_last.pth.tar\",\n",
        "                    f\"{opt.checkpoint_dir}/{opt.model_path}_best.pth.tar\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
